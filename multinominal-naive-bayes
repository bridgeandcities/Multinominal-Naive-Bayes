{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>the 4 202 353 bp genome of the alkaliphilic ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>the complete 1751377-bp sequence of the genome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>in 1992 we started assembling an ordered libra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>the aim of this study is to measure human mito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>the amino acid sequence of the spirulina maxim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id class                                           abstract\n",
       "0   1     B  the 4 202 353 bp genome of the alkaliphilic ba...\n",
       "1   2     A  the complete 1751377-bp sequence of the genome...\n",
       "2   3     E  in 1992 we started assembling an ordered libra...\n",
       "3   4     E  the aim of this study is to measure human mito...\n",
       "4   5     B  the amino acid sequence of the spirulina maxim..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load in the training set .csv\n",
    "training_set = pd.read_csv(\"trg.csv\")\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text processing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>[bp, genome, alkaliphilic, bacterium, bacillus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>[complete, bp, sequence, genome, thermophilic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>[started, assembling, ordered, library, cosmid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>[aim, study, measure, human, mitochondrial, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>[amino, acid, sequence, spirulina, maxima, fer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id class                                           abstract\n",
       "0   1     B  [bp, genome, alkaliphilic, bacterium, bacillus...\n",
       "1   2     A  [complete, bp, sequence, genome, thermophilic,...\n",
       "2   3     E  [started, assembling, ordered, library, cosmid...\n",
       "3   4     E  [aim, study, measure, human, mitochondrial, se...\n",
       "4   5     B  [amino, acid, sequence, spirulina, maxima, fer..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process the text, find a 'good model' with cross-validation\n",
    "print(\"Text processing...\")\n",
    "import re\n",
    "\n",
    "# Text processing by removing symbols\n",
    "replaceSpace = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "replaceSymbols = re.compile('[^a-z #+_]')\n",
    "stopWordsList = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "# cleans the text and splits into words with most common english words removed\n",
    "def clean_text(text):\n",
    "    text = text.lower() # lowercase text\n",
    "    text = replaceSpace.sub(' ', text) # replace symbols by space in text\n",
    "    text = replaceSymbols.sub('', text) # delete symbols from text\n",
    "    text = [word for word in text.split() if word not in stopWordsList]\n",
    "    return text\n",
    "    \n",
    "training_set['abstract'] = training_set['abstract'].apply(clean_text)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the NBC...\n",
      "total number of words in A:  16365\n",
      "total number of words in B:  173303\n",
      "total number of words in E:  230961\n",
      "total number of words in V:  13429\n",
      "total words over all classes:  434058\n",
      "unique words in A:  1792\n",
      "unique words in B:  10516\n",
      "unique words in E:  18504\n",
      "unique words in V:  2830\n",
      "33642\n"
     ]
    }
   ],
   "source": [
    "# Train the NBC with this data (your own NBC code)\n",
    "print(\"Training the NBC...\")\n",
    "\n",
    "# Create dictionaries of words in each class\n",
    "from collections import Counter\n",
    "\n",
    "bigListA = training_set.loc[training_set['class'] == 'A', 'abstract'].sum()\n",
    "bigDictA = Counter(bigListA)\n",
    "bigListB = training_set.loc[training_set['class'] == 'B', 'abstract'].sum()\n",
    "bigDictB = Counter(bigListB)\n",
    "bigListE = training_set.loc[training_set['class'] == 'E', 'abstract'].sum()\n",
    "bigDictE = Counter(bigListE)\n",
    "bigListV = training_set.loc[training_set['class'] == 'V', 'abstract'].sum()\n",
    "bigDictV = Counter(bigListV)\n",
    "\n",
    "# word list for each class\n",
    "bigListALen = len(bigListA)\n",
    "print(\"total number of words in A: \", len(bigListA))\n",
    "bigListBLen = len(bigListB)\n",
    "print(\"total number of words in B: \", len(bigListB))\n",
    "bigListELen = len(bigListE)\n",
    "print(\"total number of words in E: \", len(bigListE))\n",
    "bigListVLen = len(bigListV)\n",
    "print(\"total number of words in V: \", len(bigListV))\n",
    "\n",
    "print(\"total words over all classes: \", bigListALen + bigListBLen + bigListELen + bigListVLen)\n",
    "\n",
    "# unique dict\n",
    "bigDictALen = len(bigDictA)\n",
    "print(\"unique words in A: \", len(bigDictA))\n",
    "bigDictBLen = len(bigDictB)\n",
    "print(\"unique words in B: \", len(bigDictB))\n",
    "bigDictELen = len(bigDictE)\n",
    "print(\"unique words in E: \", len(bigDictE))\n",
    "bigDictVLen = len(bigDictV)\n",
    "print(\"unique words in V: \", len(bigDictV))\n",
    "\n",
    "uniqueOverAllClasses = len(bigDictA) + len(bigDictB) + len(bigDictE) + len(bigDictV)\n",
    "print(uniqueOverAllClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E': 2144, 'B': 1602, 'A': 128, 'V': 126}\n",
      "4000\n",
      "{'E': 0.536, 'B': 0.4005, 'A': 0.032, 'V': 0.0315}\n",
      "{'E': -0.27083521030722996, 'B': -0.39739747957974353, 'A': -1.494850021680094, 'V': -1.5016894462103996}\n"
     ]
    }
   ],
   "source": [
    "# Calculating priors P(c)\n",
    "import math\n",
    "\n",
    "classCountDict = training_set['class'].value_counts().to_dict()\n",
    "print(classCountDict)\n",
    "\n",
    "numberOfColumns = len(training_set.index)\n",
    "print(numberOfColumns)\n",
    "\n",
    "priorDict = {}\n",
    "\n",
    "# prior ratios\n",
    "for key in classCountDict:\n",
    "    prior = (classCountDict[key]/numberOfColumns)\n",
    "    #print(prior)\n",
    "    classCountDict[key] = prior\n",
    "    priorDict[key] = math.log10(prior)\n",
    "\n",
    "print(classCountDict)\n",
    "print(priorDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.699030801307797 -5.315854937870667 -5.422594763797286 -4.672753424775022\n"
     ]
    }
   ],
   "source": [
    "# Calculating conditional probabilities P(w|c)\n",
    "\n",
    "condLogDictA = {}\n",
    "condLogDictB = {}\n",
    "condLogDictE = {}\n",
    "condLogDictV = {}\n",
    "\n",
    "for word in bigDictA:\n",
    "    log_answer = math.log10((bigDictA[word] + 1) / (bigListALen + uniqueOverAllClasses))\n",
    "#   print(word, bigDictA[word], log_answer)\n",
    "    condLogDictA[word] = log_answer\n",
    "#   print(condLogDictA[word])\n",
    "for word in bigDictB:\n",
    "    log_answer = math.log10((bigDictB[word] + 1) / (bigListBLen + uniqueOverAllClasses))\n",
    "    condLogDictB[word] = log_answer\n",
    "for word in bigDictE:\n",
    "    log_answer = math.log10((bigDictE[word] + 1) / (bigListELen + uniqueOverAllClasses))\n",
    "    condLogDictE[word] = log_answer\n",
    "for word in bigDictV:\n",
    "    log_answer = math.log10((bigDictV[word] + 1) / (bigListVLen + uniqueOverAllClasses))\n",
    "    condLogDictV[word] = log_answer\n",
    "    \n",
    "condLogSmoothingA = math.log10(1 / (bigListALen + uniqueOverAllClasses))\n",
    "condLogSmoothingB = math.log10(1 / (bigListBLen + uniqueOverAllClasses))\n",
    "condLogSmoothingE = math.log10(1 / (bigListELen + uniqueOverAllClasses))\n",
    "condLogSmoothingV = math.log10(1 / (bigListVLen + uniqueOverAllClasses))\n",
    "\n",
    "print(condLogSmoothingA, condLogSmoothingB, condLogSmoothingE, condLogSmoothingV,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(abstract):\n",
    "    classifiedList = []\n",
    "    abstract = abstract.apply(clean_text)\n",
    "    #print(abstract)\n",
    "    for entry in abstract:\n",
    "        abstractClassDict = {'A':priorDict['A'], 'B':priorDict['B'], 'E':priorDict['E'], 'V':priorDict['V']}\n",
    "        for word in entry:\n",
    "            #print(\"word: \", word)\n",
    "            if condLogDictA.get(word):\n",
    "                abstractClassDict['A'] += condLogDictA[word]\n",
    "            else:\n",
    "                abstractClassDict['A'] += condLogSmoothingA\n",
    "            if condLogDictB.get(word):\n",
    "                abstractClassDict['B'] += condLogDictB[word]\n",
    "            else:\n",
    "                abstractClassDict['B'] += condLogSmoothingB\n",
    "            if condLogDictE.get(word):\n",
    "                abstractClassDict['E'] += condLogDictE[word]\n",
    "            else:\n",
    "                abstractClassDict['E'] += condLogSmoothingE\n",
    "            if condLogDictV.get(word):\n",
    "                abstractClassDict['V'] += condLogDictV[word]\n",
    "            else:\n",
    "                abstractClassDict['V'] += condLogSmoothingV\n",
    "        #print(abstractClassDict)\n",
    "        abstractClass = max(abstractClassDict,key=abstractClassDict.get)\n",
    "        #print(\"final class: \", abstractClass)\n",
    "        classifiedList.append(abstractClass)\n",
    "    #print(classifiedList)\n",
    "    return classifiedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''training'''\n",
    "# classify using multinominal naive bayes classifier\n",
    "# Use this 'good model' to generate classifications.  \n",
    "test_set = pd.read_csv(\"trg.csv\")\n",
    "\n",
    "# Apply the model to the test set\n",
    "test_set_class_predictions = classify(test_set[\"abstract\"])\n",
    "#print(test_set_class_predictions)\n",
    "test_set[\"class\"] = test_set_class_predictions\n",
    "\n",
    "\n",
    "# Write the test set classifications to a .csv so it can be submitted to Kaggle\n",
    "test_set.drop([\"abstract\"], axis = 1).to_csv(\"trg_test.csv\", index=False)\n",
    "#print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''kaggle'''\n",
    "# classify using multinominal naive bayes classifier\n",
    "test_set = pd.read_csv(\"tst.csv\")\n",
    "\n",
    "# Apply the model to the test set\n",
    "test_set_class_predictions = classify(test_set[\"abstract\"])\n",
    "#print(test_set_class_predictions)\n",
    "test_set[\"class\"] = test_set_class_predictions\n",
    "\n",
    "\n",
    "# Write the test set classifications to a .csv so it can be submitted to Kaggle\n",
    "test_set.drop([\"abstract\"], axis = 1).to_csv(\"tst_kaggle_2.csv\", index=False)\n",
    "#print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
